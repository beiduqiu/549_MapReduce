@article{howe_trackmenot:_2009,
	title = {{TrackMeNot}: Resisting Surveillance in Web Search},
	volume = {23},
	pages = {417--436},
	journaltitle = {Lessons from the Identity Trail: Anonymity, Privacy, and Identity in a Networked Society},
	author = {Howe, Daniel C and Nissenbaum, H},
	date = {2009},
	langid = {english},
	file = {Howe - TrackMeNot Resisting Surveillance in Web Search.pdf:D\:\\Zotero文件存储\\storage\\2ZBZQYM9\\Howe - TrackMeNot Resisting Surveillance in Web Search.pdf:application/pdf}
}
@article{mapreduce:_2004,
title	= {MapReduce: Simplified Data Processing on Large Clusters},
author	= {Jeffrey Dean and Sanjay Ghemawat},
year	= {2004},
booktitle	= {OSDI'04: Sixth Symposium on Operating System Design and Implementation},
pages	= {137--150},
address	= {San Francisco, CA}
}
@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}
@inproceedings{model,
author = {Karloff, Howard and Suri, Siddharth and Vassilvitskii, Sergei},
title = {A Model of Computation for MapReduce},
year = {2010},
isbn = {9780898716986},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {In recent years the MapReduce framework has emerged as one of the most widely used parallel computing platforms for processing data on terabyte and petabyte scales. Used daily at companies such as Yahoo!, Google, Amazon, and Facebook, and adopted more recently by several universities, it allows for easy parallelization of data intensive computations over many machines. One key feature of MapReduce that differentiates it from previous models of parallel computation is that it interleaves sequential and parallel computation. We propose a model of efficient computation using the MapReduce paradigm. Since MapReduce is designed for computations over massive data sets, our model limits the number of machines and the memory per machine to be substantially sublinear in the size of the input. On the other hand, we place very loose restrictions on the computational power of of any individual machine---our model allows each machine to perform sequential computations in time polynomial in the size of the original input.We compare MapReduce to the PRAM model of computation. We prove a simulation lemma showing that a large class of PRAM algorithms can be efficiently simulated via MapReduce. The strength of MapReduce, however, lies in the fact that it uses both sequential and parallel computation. We demonstrate how algorithms can take advantage of this fact to compute an MST of a dense graph in only two rounds, as opposed to Ω(log(n)) rounds needed in the standard PRAM model. We show how to evaluate a wide class of functions using the MapReduce framework. We conclude by applying this result to show how to compute some basic algorithmic problems such as undirected s-t connectivity in the MapReduce framework.},
booktitle = {Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {938–948},
numpages = {11},
location = {Austin, Texas},
series = {SODA '10}
}

